{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f33a24dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:39:44.912244Z",
     "iopub.status.busy": "2025-01-01T16:39:44.911941Z",
     "iopub.status.idle": "2025-01-01T16:39:44.924934Z",
     "shell.execute_reply": "2025-01-01T16:39:44.923991Z"
    },
    "papermill": {
     "duration": 0.018936,
     "end_time": "2025-01-01T16:39:44.926781",
     "exception": false,
     "start_time": "2025-01-01T16:39:44.907845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "directory = '/kaggle/input/lepetitprince100langues'\n",
    "input_files = glob.glob(os.path.join(directory, '*.txt'))\n",
    "results_file = 'results.csv'\n",
    "trained_files_log = 'trained_files.log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0a2483",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:39:44.931716Z",
     "iopub.status.busy": "2025-01-01T16:39:44.931452Z",
     "iopub.status.idle": "2025-01-01T16:39:53.208896Z",
     "shell.execute_reply": "2025-01-01T16:39:53.208046Z"
    },
    "papermill": {
     "duration": 8.281019,
     "end_time": "2025-01-01T16:39:53.210177",
     "exception": false,
     "start_time": "2025-01-01T16:39:44.929158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs available: 1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Enable memory growth for all GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs available: {len(gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs found\")\n",
    "\n",
    "# Verify GPU usage\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e3e738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:39:53.215292Z",
     "iopub.status.busy": "2025-01-01T16:39:53.214837Z",
     "iopub.status.idle": "2025-01-01T16:39:53.238870Z",
     "shell.execute_reply": "2025-01-01T16:39:53.238068Z"
    },
    "papermill": {
     "duration": 0.02789,
     "end_time": "2025-01-01T16:39:53.240209",
     "exception": false,
     "start_time": "2025-01-01T16:39:53.212319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94cfc54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:39:53.244848Z",
     "iopub.status.busy": "2025-01-01T16:39:53.244631Z",
     "iopub.status.idle": "2025-01-01T16:39:57.277213Z",
     "shell.execute_reply": "2025-01-01T16:39:57.276458Z"
    },
    "papermill": {
     "duration": 4.036696,
     "end_time": "2025-01-01T16:39:57.278836",
     "exception": false,
     "start_time": "2025-01-01T16:39:53.242140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer()\n",
    "tokenizer.train(\n",
    "    files=input_files,\n",
    "    vocab_size=8000,\n",
    "    min_frequency=2,\n",
    "    special_tokens=[\"<unk>\", \"<pad>\"]\n",
    ")\n",
    "tokenizer.save(\"spm_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179f87dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:39:57.286064Z",
     "iopub.status.busy": "2025-01-01T16:39:57.285786Z",
     "iopub.status.idle": "2025-01-01T16:39:57.300088Z",
     "shell.execute_reply": "2025-01-01T16:39:57.299458Z"
    },
    "papermill": {
     "duration": 0.020191,
     "end_time": "2025-01-01T16:39:57.301212",
     "exception": false,
     "start_time": "2025-01-01T16:39:57.281021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def load_text(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def create_sequences(text, sequence_length, tokenizer):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "    input_sequences = []\n",
    "    for i in range(sequence_length, len(tokens)):\n",
    "        seq = tokens[i-sequence_length:i]\n",
    "        input_sequences.append(seq)\n",
    "    return np.array(input_sequences), tokenizer.vocab_size\n",
    "\n",
    "def data_generator(input_sequences, total_words, batch_size):\n",
    "    num_samples = len(input_sequences)\n",
    "    while True:\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch = input_sequences[i:i+batch_size]\n",
    "            batch_one_hot = to_categorical_3d(batch, num_classes=total_words)\n",
    "            yield batch_one_hot, batch_one_hot\n",
    "\n",
    "def create_autoencoder(sequence_length, total_words, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Input(shape=(sequence_length, total_words)),\n",
    "        LSTM(100, return_sequences=False),\n",
    "        BatchNormalization(),\n",
    "        RepeatVector(sequence_length),\n",
    "        LSTM(100, return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        TimeDistributed(Dense(total_words, activation='softmax'))\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbbc824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:39:57.305968Z",
     "iopub.status.busy": "2025-01-01T16:39:57.305744Z",
     "iopub.status.idle": "2025-01-01T16:40:01.268980Z",
     "shell.execute_reply": "2025-01-01T16:40:01.268233Z"
    },
    "papermill": {
     "duration": 3.967278,
     "end_time": "2025-01-01T16:40:01.270518",
     "exception": false,
     "start_time": "2025-01-01T16:39:57.303240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sequence_length = 50\n",
    "epochs = 25\n",
    "\n",
    "def to_categorical_3d(y, num_classes):\n",
    "    batch_size, sequence_length = y.shape\n",
    "    one_hot = np.zeros((batch_size, sequence_length, num_classes), dtype=np.float32)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(sequence_length):\n",
    "            one_hot[i, j, y[i, j]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def data_generator(input_sequences, total_words, batch_size):\n",
    "    num_samples = len(input_sequences)\n",
    "    while True:\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch = input_sequences[i:i+batch_size]\n",
    "            batch_one_hot = to_categorical_3d(batch, num_classes=total_words)\n",
    "            yield batch_one_hot, batch_one_hot\n",
    "\n",
    "processed_files = {}\n",
    "if os.path.exists(trained_files_log):\n",
    "    with open(trained_files_log, 'r') as f:\n",
    "        for line in f:\n",
    "            filename, beginning_loss, final_loss = line.strip().split(': ')\n",
    "            processed_files[filename] = (float(beginning_loss), float(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "014ab9c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-01T16:40:01.275542Z",
     "iopub.status.busy": "2025-01-01T16:40:01.275097Z",
     "iopub.status.idle": "2025-01-02T00:53:04.575414Z",
     "shell.execute_reply": "2025-01-02T00:53:04.574507Z"
    },
    "papermill": {
     "duration": 29583.304208,
     "end_time": "2025-01-02T00:53:04.576879",
     "exception": false,
     "start_time": "2025-01-01T16:40:01.272671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 152ms/step - accuracy: 0.0248 - loss: 7.6988 - val_accuracy: 0.0262 - val_loss: 5.4624\n",
      "Epoch 2/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.0407 - loss: 4.9579 - val_accuracy: 0.0323 - val_loss: 5.0106\n",
      "Epoch 3/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 147ms/step - accuracy: 0.0467 - loss: 4.5497 - val_accuracy: 0.0412 - val_loss: 4.5498\n",
      "Epoch 4/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.0494 - loss: 4.2698 - val_accuracy: 0.0410 - val_loss: 4.4190\n",
      "Epoch 5/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 147ms/step - accuracy: 0.0507 - loss: 4.1246 - val_accuracy: 0.0322 - val_loss: 4.6973\n",
      "Epoch 6/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 147ms/step - accuracy: 0.0519 - loss: 4.0223 - val_accuracy: 0.0176 - val_loss: 5.9406\n",
      "Epoch 7/25\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 146ms/step - accuracy: 0.0544 - loss: 3.9423 - val_accuracy: 0.0243 - val_loss: 5.5756\n",
      "Processed cleaned_5. Le PP en bulgare.txt: normalized beginning validation loss = 0.6078022119175661, normalized final validation loss = 0.6203892805535\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 148ms/step - accuracy: 0.0254 - loss: 7.3163 - val_accuracy: 0.0195 - val_loss: 6.1507\n",
      "Epoch 2/25\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 146ms/step - accuracy: 0.0434 - loss: 4.6194 - val_accuracy: 0.0149 - val_loss: 7.1621\n",
      "Epoch 3/25\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 144ms/step - accuracy: 0.0424 - loss: 4.2835 - val_accuracy: 0.0111 - val_loss: 8.4158\n",
      "Epoch 4/25\n",
      "\u001b[1m498/498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 145ms/step - accuracy: 0.0443 - loss: 4.1485 - val_accuracy: 0.0145 - val_loss: 7.7937\n",
      "Processed cleaned_19. Le PP en Twents.txt: normalized beginning validation loss = 0.6843809432032, normalized final validation loss = 0.867202948677313\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 145ms/step - accuracy: 0.0340 - loss: 7.1423 - val_accuracy: 0.0157 - val_loss: 6.4757\n",
      "Epoch 2/25\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - accuracy: 0.0509 - loss: 4.5487 - val_accuracy: 0.0181 - val_loss: 6.7988\n",
      "Epoch 3/25\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - accuracy: 0.0490 - loss: 4.2241 - val_accuracy: 0.0127 - val_loss: 8.4629\n",
      "Epoch 4/25\n",
      "\u001b[1m582/582\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 144ms/step - accuracy: 0.0509 - loss: 4.0977 - val_accuracy: 0.0154 - val_loss: 7.2455\n",
      "Processed cleaned_7. Le PP en roumain.txt: normalized beginning validation loss = 0.7205471380151115, normalized final validation loss = 0.8061993718135995\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 131ms/step - accuracy: 0.0468 - loss: 7.3882 - val_accuracy: 0.0451 - val_loss: 5.2752\n",
      "Epoch 2/25\n",
      "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 129ms/step - accuracy: 0.0695 - loss: 4.4798 - val_accuracy: 0.0209 - val_loss: 5.9765\n",
      "Epoch 3/25\n",
      "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 129ms/step - accuracy: 0.0678 - loss: 4.0811 - val_accuracy: 0.0161 - val_loss: 6.7395\n",
      "Epoch 4/25\n",
      "\u001b[1m403/403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 128ms/step - accuracy: 0.0671 - loss: 3.9271 - val_accuracy: 0.0157 - val_loss: 6.9077\n",
      "Processed cleaned_68. Le PP en bribri.txt: normalized beginning validation loss = 0.5869712990917917, normalized final validation loss = 0.7686132022175984\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 139ms/step - accuracy: 0.0229 - loss: 7.6113 - val_accuracy: 0.0210 - val_loss: 5.8547\n",
      "Epoch 2/25\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 137ms/step - accuracy: 0.0424 - loss: 4.8374 - val_accuracy: 0.0129 - val_loss: 6.9349\n",
      "Epoch 3/25\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 134ms/step - accuracy: 0.0424 - loss: 4.3517 - val_accuracy: 0.0214 - val_loss: 5.9358\n",
      "Epoch 4/25\n",
      "\u001b[1m394/394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 135ms/step - accuracy: 0.0434 - loss: 4.1740 - val_accuracy: 0.0210 - val_loss: 6.8595\n",
      "Processed cleaned_PP-2813_sambahsa.txt: normalized beginning validation loss = 0.651453530319517, normalized final validation loss = 0.7632559450370017\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 138ms/step - accuracy: 0.0283 - loss: 7.4713 - val_accuracy: 0.0363 - val_loss: 5.7508\n",
      "Epoch 2/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 137ms/step - accuracy: 0.0474 - loss: 4.7364 - val_accuracy: 0.0119 - val_loss: 7.4936\n",
      "Epoch 3/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 138ms/step - accuracy: 0.0469 - loss: 4.2864 - val_accuracy: 0.0147 - val_loss: 6.9913\n",
      "Epoch 4/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 136ms/step - accuracy: 0.0473 - loss: 4.1257 - val_accuracy: 0.0176 - val_loss: 8.3415\n",
      "Processed cleaned_50. Le PP en Scots.txt: normalized beginning validation loss = 0.6398845798367012, normalized final validation loss = 0.9281485338196571\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 148ms/step - accuracy: 0.0312 - loss: 6.8881 - val_accuracy: 0.0053 - val_loss: 6.5970\n",
      "Epoch 2/25\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 147ms/step - accuracy: 0.0459 - loss: 4.4911 - val_accuracy: 0.0197 - val_loss: 6.4970\n",
      "Epoch 3/25\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 147ms/step - accuracy: 0.0450 - loss: 4.2474 - val_accuracy: 0.0118 - val_loss: 7.0502\n",
      "Epoch 4/25\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 146ms/step - accuracy: 0.0475 - loss: 4.1388 - val_accuracy: 0.0133 - val_loss: 7.5691\n",
      "Epoch 5/25\n",
      "\u001b[1m697/697\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 146ms/step - accuracy: 0.0539 - loss: 4.0186 - val_accuracy: 0.0123 - val_loss: 8.4362\n",
      "Processed cleaned_79. Le PP en Lule Saame.txt: normalized beginning validation loss = 0.7340421776737306, normalized final validation loss = 0.9386943256978179\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 149ms/step - accuracy: 0.0351 - loss: 7.4439 - val_accuracy: 0.0436 - val_loss: 5.2031\n",
      "Epoch 2/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 147ms/step - accuracy: 0.0648 - loss: 4.3923 - val_accuracy: 0.0174 - val_loss: 6.0873\n",
      "Epoch 3/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 146ms/step - accuracy: 0.0648 - loss: 4.0646 - val_accuracy: 0.0156 - val_loss: 6.3862\n",
      "Epoch 4/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 146ms/step - accuracy: 0.0659 - loss: 3.9296 - val_accuracy: 0.0159 - val_loss: 7.7072\n",
      "Processed cleaned_PP-6039  Ourdou.txt: normalized beginning validation loss = 0.5789472185889704, normalized final validation loss = 0.8575755270692194\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 149ms/step - accuracy: 0.0255 - loss: 7.3616 - val_accuracy: 0.0122 - val_loss: 6.0944\n",
      "Epoch 2/25\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 146ms/step - accuracy: 0.0438 - loss: 4.7266 - val_accuracy: 0.0145 - val_loss: 6.4087\n",
      "Epoch 3/25\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 147ms/step - accuracy: 0.0432 - loss: 4.3038 - val_accuracy: 0.0170 - val_loss: 7.5568\n",
      "Epoch 4/25\n",
      "\u001b[1m499/499\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 147ms/step - accuracy: 0.0442 - loss: 4.1514 - val_accuracy: 0.0161 - val_loss: 8.4699\n",
      "Processed cleaned_11. Le Petit Prince en Franais.txt: normalized beginning validation loss = 0.6781241511240697, normalized final validation loss = 0.9424432543789898\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - accuracy: 0.0280 - loss: 7.2555 - val_accuracy: 0.0142 - val_loss: 6.2311\n",
      "Epoch 2/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 146ms/step - accuracy: 0.0453 - loss: 4.5973 - val_accuracy: 0.0171 - val_loss: 7.4971\n",
      "Epoch 3/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 148ms/step - accuracy: 0.0444 - loss: 4.2591 - val_accuracy: 0.0126 - val_loss: 8.3358\n",
      "Epoch 4/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 146ms/step - accuracy: 0.0470 - loss: 4.1229 - val_accuracy: 0.0173 - val_loss: 7.8270\n",
      "Processed cleaned_10. Le PP en czecque.txt: normalized beginning validation loss = 0.6933342707399318, normalized final validation loss = 0.8709058766060354\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 151ms/step - accuracy: 0.0325 - loss: 7.4032 - val_accuracy: 0.0325 - val_loss: 5.8485\n",
      "Epoch 2/25\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 153ms/step - accuracy: 0.0487 - loss: 4.6913 - val_accuracy: 0.0144 - val_loss: 6.3461\n",
      "Epoch 3/25\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 150ms/step - accuracy: 0.0476 - loss: 4.2559 - val_accuracy: 0.0163 - val_loss: 6.7079\n",
      "Epoch 4/25\n",
      "\u001b[1m468/468\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 151ms/step - accuracy: 0.0486 - loss: 4.0994 - val_accuracy: 0.0212 - val_loss: 6.5616\n",
      "Processed cleaned_PP-0726_ido.txt: normalized beginning validation loss = 0.6507569399170842, normalized final validation loss = 0.7301044708181466\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 151ms/step - accuracy: 0.0298 - loss: 7.2929 - val_accuracy: 0.0115 - val_loss: 5.5745\n",
      "Epoch 2/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 148ms/step - accuracy: 0.0499 - loss: 4.5184 - val_accuracy: 0.0180 - val_loss: 6.0866\n",
      "Epoch 3/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 145ms/step - accuracy: 0.0498 - loss: 4.2182 - val_accuracy: 0.0166 - val_loss: 7.1240\n",
      "Epoch 4/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 144ms/step - accuracy: 0.0513 - loss: 4.0856 - val_accuracy: 0.0114 - val_loss: 8.1129\n",
      "Processed cleaned_78. Le PP en Interslavic_cyrillic.txt: normalized beginning validation loss = 0.6202747296601453, normalized final validation loss = 0.9027199333312407\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 144ms/step - accuracy: 0.0325 - loss: 6.8985 - val_accuracy: 0.0097 - val_loss: 6.2364\n",
      "Epoch 2/25\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 141ms/step - accuracy: 0.0534 - loss: 4.3909 - val_accuracy: 0.0211 - val_loss: 6.6406\n",
      "Epoch 3/25\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 143ms/step - accuracy: 0.0524 - loss: 4.1585 - val_accuracy: 0.0036 - val_loss: 7.9373\n",
      "Epoch 4/25\n",
      "\u001b[1m587/587\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 143ms/step - accuracy: 0.0531 - loss: 4.0637 - val_accuracy: 0.0133 - val_loss: 7.8741\n",
      "Processed cleaned_41. Le PP en Dzonkha.txt: normalized beginning validation loss = 0.6939240035697772, normalized final validation loss = 0.8761413140315871\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 149ms/step - accuracy: 0.0299 - loss: 7.0878 - val_accuracy: 0.0115 - val_loss: 6.3681\n",
      "Epoch 2/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 145ms/step - accuracy: 0.0470 - loss: 4.5337 - val_accuracy: 0.0182 - val_loss: 7.3105\n",
      "Epoch 3/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 146ms/step - accuracy: 0.0467 - loss: 4.2420 - val_accuracy: 0.0147 - val_loss: 8.0351\n",
      "Epoch 4/25\n",
      "\u001b[1m571/571\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 146ms/step - accuracy: 0.0498 - loss: 4.1071 - val_accuracy: 0.0144 - val_loss: 8.1876\n",
      "Processed cleaned_45. Le PP en Wayuunaiki.txt: normalized beginning validation loss = 0.7085799388034769, normalized final validation loss = 0.9110331765801402\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 148ms/step - accuracy: 0.0306 - loss: 7.4160 - val_accuracy: 0.0310 - val_loss: 5.6828\n",
      "Epoch 2/25\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 146ms/step - accuracy: 0.0479 - loss: 4.6971 - val_accuracy: 0.0105 - val_loss: 6.8583\n",
      "Epoch 3/25\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 145ms/step - accuracy: 0.0473 - loss: 4.2611 - val_accuracy: 0.0163 - val_loss: 6.8851\n",
      "Epoch 4/25\n",
      "\u001b[1m438/438\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 146ms/step - accuracy: 0.0488 - loss: 4.0992 - val_accuracy: 0.0103 - val_loss: 8.1811\n",
      "Processed cleaned_46. Le PP en Haut-valaisan.txt: normalized beginning validation loss = 0.6323241678179122, normalized final validation loss = 0.9103010907874088\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 148ms/step - accuracy: 0.0333 - loss: 6.9690 - val_accuracy: 0.0206 - val_loss: 6.2307\n",
      "Epoch 2/25\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 146ms/step - accuracy: 0.0486 - loss: 4.4994 - val_accuracy: 0.0149 - val_loss: 6.6045\n",
      "Epoch 3/25\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 145ms/step - accuracy: 0.0473 - loss: 4.2326 - val_accuracy: 0.0176 - val_loss: 6.7018\n",
      "Epoch 4/25\n",
      "\u001b[1m622/622\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 145ms/step - accuracy: 0.0481 - loss: 4.1267 - val_accuracy: 0.0100 - val_loss: 7.6479\n",
      "Processed cleaned_55. Le PP en totonaque de la Sierra.txt: normalized beginning validation loss = 0.6932905514550202, normalized final validation loss = 0.8509769393184862\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 147ms/step - accuracy: 0.0417 - loss: 6.3579 - val_accuracy: 0.0261 - val_loss: 7.4786\n",
      "Epoch 2/25\n",
      "\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 146ms/step - accuracy: 0.0543 - loss: 4.3336 - val_accuracy: 0.0165 - val_loss: 7.8761\n",
      "Epoch 3/25\n",
      "\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 146ms/step - accuracy: 0.0547 - loss: 4.1768 - val_accuracy: 0.0110 - val_loss: 8.1166\n",
      "Epoch 4/25\n",
      "\u001b[1m1042/1042\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 146ms/step - accuracy: 0.0566 - loss: 4.0985 - val_accuracy: 0.0146 - val_loss: 7.5923\n",
      "Processed cleaned_PP-1612 bouriate.txt: normalized beginning validation loss = 0.8321355723004983, normalized final validation loss = 0.8447925705693369\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 144ms/step - accuracy: 0.0273 - loss: 7.6799 - val_accuracy: 0.0189 - val_loss: 5.8221\n",
      "Epoch 2/25\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 142ms/step - accuracy: 0.0486 - loss: 4.7393 - val_accuracy: 0.0149 - val_loss: 6.0833\n",
      "Epoch 3/25\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 142ms/step - accuracy: 0.0483 - loss: 4.2511 - val_accuracy: 0.0152 - val_loss: 6.5509\n",
      "Epoch 4/25\n",
      "\u001b[1m332/332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 141ms/step - accuracy: 0.0493 - loss: 4.0766 - val_accuracy: 0.0183 - val_loss: 7.0507\n",
      "Processed cleaned_16. Le PP en anglais.txt: normalized beginning validation loss = 0.6478163404903159, normalized final validation loss = 0.7845238915397386\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 148ms/step - accuracy: 0.0401 - loss: 7.3701 - val_accuracy: 0.0435 - val_loss: 5.8429\n",
      "Epoch 2/25\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 145ms/step - accuracy: 0.0570 - loss: 4.5747 - val_accuracy: 0.0192 - val_loss: 6.5208\n",
      "Epoch 3/25\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 145ms/step - accuracy: 0.0549 - loss: 4.1951 - val_accuracy: 0.0179 - val_loss: 7.2125\n",
      "Epoch 4/25\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 146ms/step - accuracy: 0.0563 - loss: 4.0476 - val_accuracy: 0.0058 - val_loss: 9.3255\n",
      "Processed cleaned_17. Le PP en Berbere amazighe.txt: normalized beginning validation loss = 0.6501334095332475, normalized final validation loss = 1.0376383893719012\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 148ms/step - accuracy: 0.0534 - loss: 6.6596 - val_accuracy: 0.0277 - val_loss: 5.1916\n",
      "Epoch 2/25\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 146ms/step - accuracy: 0.0725 - loss: 4.0368 - val_accuracy: 0.0363 - val_loss: 5.2628\n",
      "Epoch 3/25\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 147ms/step - accuracy: 0.0715 - loss: 3.8484 - val_accuracy: 0.0215 - val_loss: 6.0034\n",
      "Epoch 4/25\n",
      "\u001b[1m595/595\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 146ms/step - accuracy: 0.0733 - loss: 3.7622 - val_accuracy: 0.0330 - val_loss: 6.2918\n",
      "Processed cleaned_88. Le PP en Cham.txt: normalized beginning validation loss = 0.5776616912174609, normalized final validation loss = 0.7000823211430873\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 148ms/step - accuracy: 0.0415 - loss: 6.7925 - val_accuracy: 0.0447 - val_loss: 4.7370\n",
      "Epoch 2/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 146ms/step - accuracy: 0.0628 - loss: 4.3177 - val_accuracy: 0.0168 - val_loss: 5.3948\n",
      "Epoch 3/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 146ms/step - accuracy: 0.0712 - loss: 4.0222 - val_accuracy: 0.0349 - val_loss: 5.4838\n",
      "Epoch 4/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 146ms/step - accuracy: 0.0742 - loss: 3.8481 - val_accuracy: 0.0383 - val_loss: 5.2768\n",
      "Processed cleaned_53. Le PP en Lanna.txt: normalized beginning validation loss = 0.5270836251410167, normalized final validation loss = 0.5871428866735928\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 144ms/step - accuracy: 0.0247 - loss: 7.4681 - val_accuracy: 0.0203 - val_loss: 5.8536\n",
      "Epoch 2/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 143ms/step - accuracy: 0.0418 - loss: 4.7408 - val_accuracy: 0.0150 - val_loss: 7.1181\n",
      "Epoch 3/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 142ms/step - accuracy: 0.0420 - loss: 4.3070 - val_accuracy: 0.0130 - val_loss: 7.2378\n",
      "Epoch 4/25\n",
      "\u001b[1m415/415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 141ms/step - accuracy: 0.0446 - loss: 4.1371 - val_accuracy: 0.0188 - val_loss: 7.3049\n",
      "Processed cleaned_59. Le PP en Rumantsch Grischun.txt: normalized beginning validation loss = 0.6513313922201645, normalized final validation loss = 0.8128124972877134\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 148ms/step - accuracy: 0.0493 - loss: 7.1263 - val_accuracy: 0.0301 - val_loss: 4.5322\n",
      "Epoch 2/25\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 147ms/step - accuracy: 0.0748 - loss: 3.8995 - val_accuracy: 0.0267 - val_loss: 5.3184\n",
      "Epoch 3/25\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 146ms/step - accuracy: 0.0775 - loss: 3.7208 - val_accuracy: 0.0287 - val_loss: 5.7430\n",
      "Epoch 4/25\n",
      "\u001b[1m388/388\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 146ms/step - accuracy: 0.0813 - loss: 3.6284 - val_accuracy: 0.0157 - val_loss: 6.5736\n",
      "Processed cleaned_PP-3546_tatar.txt: normalized beginning validation loss = 0.5042918174951404, normalized final validation loss = 0.7314407741067197\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 149ms/step - accuracy: 0.0553 - loss: 7.1734 - val_accuracy: 0.0489 - val_loss: 4.8363\n",
      "Epoch 2/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 146ms/step - accuracy: 0.0794 - loss: 4.0045 - val_accuracy: 0.0199 - val_loss: 5.9380\n",
      "Epoch 3/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 145ms/step - accuracy: 0.0793 - loss: 3.7672 - val_accuracy: 0.0246 - val_loss: 5.8785\n",
      "Epoch 4/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 147ms/step - accuracy: 0.0806 - loss: 3.6706 - val_accuracy: 0.0159 - val_loss: 6.3997\n",
      "Processed cleaned_PP-0748_arabe_algerien.txt: normalized beginning validation loss = 0.5381336213450454, normalized final validation loss = 0.7120870849830198\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 148ms/step - accuracy: 0.0325 - loss: 6.8960 - val_accuracy: 0.0130 - val_loss: 5.8973\n",
      "Epoch 2/25\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 146ms/step - accuracy: 0.0526 - loss: 4.3591 - val_accuracy: 0.0167 - val_loss: 6.5007\n",
      "Epoch 3/25\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 146ms/step - accuracy: 0.0525 - loss: 4.1282 - val_accuracy: 0.0192 - val_loss: 6.7411\n",
      "Epoch 4/25\n",
      "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 146ms/step - accuracy: 0.0562 - loss: 4.0194 - val_accuracy: 0.0097 - val_loss: 7.6119\n",
      "Processed cleaned_28. Le PP en azerbaijani.txt: normalized beginning validation loss = 0.6561864612555082, normalized final validation loss = 0.8469713720679969\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 148ms/step - accuracy: 0.0437 - loss: 7.2978 - val_accuracy: 0.0438 - val_loss: 5.7499\n",
      "Epoch 2/25\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 147ms/step - accuracy: 0.0613 - loss: 4.4875 - val_accuracy: 0.0184 - val_loss: 6.2562\n",
      "Epoch 3/25\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 147ms/step - accuracy: 0.0583 - loss: 4.1234 - val_accuracy: 0.0107 - val_loss: 7.3593\n",
      "Epoch 4/25\n",
      "\u001b[1m476/476\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 147ms/step - accuracy: 0.0584 - loss: 3.9947 - val_accuracy: 0.0111 - val_loss: 7.9972\n",
      "Processed cleaned_86. Le PP en Hiligaynon.txt: normalized beginning validation loss = 0.639784885011035, normalized final validation loss = 0.8898448161543054\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 148ms/step - accuracy: 0.0333 - loss: 7.1122 - val_accuracy: 0.0137 - val_loss: 5.8315\n",
      "Epoch 2/25\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 146ms/step - accuracy: 0.0522 - loss: 4.4215 - val_accuracy: 0.0197 - val_loss: 6.7917\n",
      "Epoch 3/25\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 146ms/step - accuracy: 0.0519 - loss: 4.1513 - val_accuracy: 0.0266 - val_loss: 6.4693\n",
      "Epoch 4/25\n",
      "\u001b[1m477/477\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 147ms/step - accuracy: 0.0552 - loss: 4.0224 - val_accuracy: 0.0181 - val_loss: 6.6114\n",
      "Processed cleaned_29. Le PP en belarusse.txt: normalized beginning validation loss = 0.6488700070911169, normalized final validation loss = 0.7356506122879246\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m463/463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 148ms/step - accuracy: 0.0371 - loss: 7.3561 - val_accuracy: 0.0399 - val_loss: 5.8086\n",
      "Epoch 2/25\n",
      "\u001b[1m463/463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 147ms/step - accuracy: 0.0550 - loss: 4.6053 - val_accuracy: 0.0168 - val_loss: 6.1552\n",
      "Epoch 3/25\n",
      "\u001b[1m463/463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 147ms/step - accuracy: 0.0525 - loss: 4.2140 - val_accuracy: 0.0164 - val_loss: 6.7680\n",
      "Epoch 4/25\n",
      "\u001b[1m463/463\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 147ms/step - accuracy: 0.0537 - loss: 4.0667 - val_accuracy: 0.0148 - val_loss: 7.1352\n",
      "Processed cleaned_51. Le PP en Patois Vaudois.txt: normalized beginning validation loss = 0.6463216609087075, normalized final validation loss = 0.7939319208625051\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 148ms/step - accuracy: 0.0251 - loss: 7.4006 - val_accuracy: 0.0172 - val_loss: 6.0311\n",
      "Epoch 2/25\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 147ms/step - accuracy: 0.0434 - loss: 4.6780 - val_accuracy: 0.0145 - val_loss: 6.8364\n",
      "Epoch 3/25\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 147ms/step - accuracy: 0.0424 - loss: 4.2977 - val_accuracy: 0.0114 - val_loss: 8.5801\n",
      "Epoch 4/25\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 146ms/step - accuracy: 0.0452 - loss: 4.1477 - val_accuracy: 0.0115 - val_loss: 8.3064\n",
      "Processed cleaned_77. Le PP en Interslavic_latin.txt: normalized beginning validation loss = 0.6710792446540688, normalized final validation loss = 0.924244253116372\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 143ms/step - accuracy: 0.0325 - loss: 6.9065 - val_accuracy: 0.0154 - val_loss: 6.9386\n",
      "Epoch 2/25\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 142ms/step - accuracy: 0.0442 - loss: 4.5508 - val_accuracy: 0.0145 - val_loss: 7.1377\n",
      "Epoch 3/25\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 143ms/step - accuracy: 0.0432 - loss: 4.2768 - val_accuracy: 0.0135 - val_loss: 7.2381\n",
      "Epoch 4/25\n",
      "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 142ms/step - accuracy: 0.0438 - loss: 4.1753 - val_accuracy: 0.0170 - val_loss: 7.1889\n",
      "Processed cleaned_66. Le PP en turc dialecte de Denizli.txt: normalized beginning validation loss = 0.7720510554528518, normalized final validation loss = 0.7999001868841725\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.1508 - loss: 8.7189 - val_accuracy: 0.3579 - val_loss: 7.5084\n",
      "Epoch 2/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - accuracy: 0.3125 - loss: 6.3359 - val_accuracy: 0.3506 - val_loss: 5.3403\n",
      "Epoch 3/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 149ms/step - accuracy: 0.3274 - loss: 5.1001 - val_accuracy: 0.3491 - val_loss: 4.2709\n",
      "Epoch 4/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - accuracy: 0.3324 - loss: 4.3718 - val_accuracy: 0.3583 - val_loss: 3.4525\n",
      "Epoch 5/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.3275 - loss: 3.9848 - val_accuracy: 0.3604 - val_loss: 3.5165\n",
      "Epoch 6/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 146ms/step - accuracy: 0.3551 - loss: 3.3605 - val_accuracy: 0.3592 - val_loss: 3.2685\n",
      "Epoch 7/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.3628 - loss: 3.2154 - val_accuracy: 0.3592 - val_loss: 3.6154\n",
      "Epoch 8/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 144ms/step - accuracy: 0.3645 - loss: 3.1700 - val_accuracy: 0.3584 - val_loss: 3.2847\n",
      "Epoch 9/25\n",
      "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 145ms/step - accuracy: 0.3655 - loss: 3.1439 - val_accuracy: 0.0483 - val_loss: 5.3364\n",
      "Processed cleaned_30. Le PP en chinois.txt: normalized beginning validation loss = 0.8354574420930128, normalized final validation loss = 0.5937755372652402\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 148ms/step - accuracy: 0.0393 - loss: 7.1754 - val_accuracy: 0.0369 - val_loss: 6.0550\n",
      "Epoch 2/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.0550 - loss: 4.5049 - val_accuracy: 0.0102 - val_loss: 6.8903\n",
      "Epoch 3/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.0525 - loss: 4.1741 - val_accuracy: 0.0147 - val_loss: 8.1091\n",
      "Epoch 4/25\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.0540 - loss: 4.0446 - val_accuracy: 0.0124 - val_loss: 8.0781\n",
      "Processed cleaned_20. Le PP en Chamorro.txt: normalized beginning validation loss = 0.6737325914006045, normalized final validation loss = 0.8988446219599481\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 134ms/step - accuracy: 0.0267 - loss: 7.1392 - val_accuracy: 0.0206 - val_loss: 5.6788\n",
      "Epoch 2/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 131ms/step - accuracy: 0.0482 - loss: 4.5082 - val_accuracy: 0.0090 - val_loss: 6.7604\n",
      "Epoch 3/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 129ms/step - accuracy: 0.0484 - loss: 4.2297 - val_accuracy: 0.0126 - val_loss: 7.3197\n",
      "Epoch 4/25\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 129ms/step - accuracy: 0.0510 - loss: 4.0975 - val_accuracy: 0.0128 - val_loss: 7.4875\n",
      "Processed cleaned_69. Le PP en Oudmourte.txt: normalized beginning validation loss = 0.6318756206884913, normalized final validation loss = 0.8331351734263903\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 149ms/step - accuracy: 0.0242 - loss: 7.1857 - val_accuracy: 0.0114 - val_loss: 5.9860\n",
      "Epoch 2/25\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 142ms/step - accuracy: 0.0442 - loss: 4.5960 - val_accuracy: 0.0122 - val_loss: 7.4517\n",
      "Epoch 3/25\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 138ms/step - accuracy: 0.0441 - loss: 4.2747 - val_accuracy: 0.0125 - val_loss: 7.7647\n",
      "Epoch 4/25\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 138ms/step - accuracy: 0.0462 - loss: 4.1467 - val_accuracy: 0.0110 - val_loss: 8.0646\n",
      "Processed cleaned_49. Le PP en Bemba.txt: normalized beginning validation loss = 0.6660574162589226, normalized final validation loss = 0.8973381105815734\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 150ms/step - accuracy: 0.0343 - loss: 7.9859 - val_accuracy: 0.0368 - val_loss: 5.0554\n",
      "Epoch 2/25\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 147ms/step - accuracy: 0.0563 - loss: 4.7171 - val_accuracy: 0.0371 - val_loss: 5.0079\n",
      "Epoch 3/25\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 148ms/step - accuracy: 0.0632 - loss: 4.3826 - val_accuracy: 0.0557 - val_loss: 4.4767\n",
      "Epoch 4/25\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 146ms/step - accuracy: 0.0673 - loss: 4.1507 - val_accuracy: 0.0460 - val_loss: 4.8268\n",
      "Epoch 5/25\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 147ms/step - accuracy: 0.0704 - loss: 3.9925 - val_accuracy: 0.0300 - val_loss: 5.4868\n",
      "Epoch 6/25\n",
      "\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 147ms/step - accuracy: 0.0733 - loss: 3.8725 - val_accuracy: 0.0323 - val_loss: 5.0925\n",
      "Processed cleaned_12. Le PP en Toki Pona.txt: normalized beginning validation loss = 0.5625145507171208, normalized final validation loss = 0.5666348810905031\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 138ms/step - accuracy: 0.0372 - loss: 7.3123 - val_accuracy: 0.0439 - val_loss: 5.6280\n",
      "Epoch 2/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 138ms/step - accuracy: 0.0546 - loss: 4.5725 - val_accuracy: 0.0130 - val_loss: 7.1057\n",
      "Epoch 3/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 137ms/step - accuracy: 0.0524 - loss: 4.1978 - val_accuracy: 0.0150 - val_loss: 7.0867\n",
      "Epoch 4/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 136ms/step - accuracy: 0.0534 - loss: 4.0601 - val_accuracy: 0.0158 - val_loss: 6.9380\n",
      "Processed cleaned_52. Le PP en Patois Fribourgeois.txt: normalized beginning validation loss = 0.6262274498681246, normalized final validation loss = 0.7719856887550227\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 142ms/step - accuracy: 0.0248 - loss: 7.2343 - val_accuracy: 0.0171 - val_loss: 5.8531\n",
      "Epoch 2/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 143ms/step - accuracy: 0.0447 - loss: 4.6064 - val_accuracy: 0.0165 - val_loss: 6.3933\n",
      "Epoch 3/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 141ms/step - accuracy: 0.0445 - loss: 4.2406 - val_accuracy: 0.0114 - val_loss: 7.5952\n",
      "Epoch 4/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 142ms/step - accuracy: 0.0474 - loss: 4.1023 - val_accuracy: 0.0184 - val_loss: 6.7573\n",
      "Processed cleaned_58. Le PP en Soundanais.txt: normalized beginning validation loss = 0.6512677764160273, normalized final validation loss = 0.7518861719759797\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 137ms/step - accuracy: 0.0382 - loss: 7.1198 - val_accuracy: 0.0437 - val_loss: 5.5345\n",
      "Epoch 2/25\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 137ms/step - accuracy: 0.0530 - loss: 4.8386 - val_accuracy: 0.0259 - val_loss: 5.4388\n",
      "Epoch 3/25\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 135ms/step - accuracy: 0.0553 - loss: 4.3045 - val_accuracy: 0.0232 - val_loss: 5.5675\n",
      "Epoch 4/25\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 137ms/step - accuracy: 0.0545 - loss: 4.1088 - val_accuracy: 0.0202 - val_loss: 6.5111\n",
      "Epoch 5/25\n",
      "\u001b[1m554/554\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 136ms/step - accuracy: 0.0555 - loss: 4.0142 - val_accuracy: 0.0132 - val_loss: 7.6931\n",
      "Processed cleaned_PP-0328_quichua-ou-kichwa.txt: normalized beginning validation loss = 0.6158157340008518, normalized final validation loss = 0.8560069916082456\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 134ms/step - accuracy: 0.0202 - loss: 7.8136 - val_accuracy: 0.0212 - val_loss: 6.0667\n",
      "Epoch 2/25\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.0417 - loss: 4.8673 - val_accuracy: 0.0169 - val_loss: 6.4248\n",
      "Epoch 3/25\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 130ms/step - accuracy: 0.0432 - loss: 4.3552 - val_accuracy: 0.0111 - val_loss: 7.6163\n",
      "Epoch 4/25\n",
      "\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 127ms/step - accuracy: 0.0464 - loss: 4.1496 - val_accuracy: 0.0130 - val_loss: 7.4954\n",
      "Processed cleaned_61. Le PP en Italien (CSS).txt: normalized beginning validation loss = 0.6750393947833392, normalized final validation loss = 0.8340072245997003\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 136ms/step - accuracy: 0.1178 - loss: 8.4809 - val_accuracy: 0.2224 - val_loss: 5.8493\n",
      "Epoch 2/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 128ms/step - accuracy: 0.2071 - loss: 5.4059 - val_accuracy: 0.2375 - val_loss: 3.4941\n",
      "Epoch 3/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 128ms/step - accuracy: 0.2475 - loss: 3.3348 - val_accuracy: 0.2222 - val_loss: 3.3258\n",
      "Epoch 4/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 126ms/step - accuracy: 0.2516 - loss: 3.1858 - val_accuracy: 0.2279 - val_loss: 3.3218\n",
      "Epoch 5/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 128ms/step - accuracy: 0.2534 - loss: 3.1143 - val_accuracy: 0.2416 - val_loss: 3.2991\n",
      "Epoch 6/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 129ms/step - accuracy: 0.2546 - loss: 3.0533 - val_accuracy: 0.0526 - val_loss: 4.4731\n",
      "Epoch 7/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 127ms/step - accuracy: 0.2561 - loss: 2.9932 - val_accuracy: 0.1147 - val_loss: 4.0447\n",
      "Epoch 8/25\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 129ms/step - accuracy: 0.2561 - loss: 2.9511 - val_accuracy: 0.1822 - val_loss: 3.9720\n",
      "Processed cleaned_35. Le PP en coreen.txt: normalized beginning validation loss = 0.6508527615536744, normalized final validation loss = 0.4419589674463136\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 148ms/step - accuracy: 0.0290 - loss: 6.5014 - val_accuracy: 0.0110 - val_loss: 7.5199\n",
      "Epoch 2/25\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 147ms/step - accuracy: 0.0438 - loss: 4.4478 - val_accuracy: 0.0128 - val_loss: 8.0929\n",
      "Epoch 3/25\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 147ms/step - accuracy: 0.0447 - loss: 4.2777 - val_accuracy: 0.0154 - val_loss: 8.1119\n",
      "Epoch 4/25\n",
      "\u001b[1m932/932\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 148ms/step - accuracy: 0.0494 - loss: 4.1696 - val_accuracy: 0.0160 - val_loss: 7.7402\n",
      "Processed cleaned_73. Le PP en Bouriate.txt: normalized beginning validation loss = 0.8367359128323703, normalized final validation loss = 0.8612486367477957\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 150ms/step - accuracy: 0.0464 - loss: 7.4319 - val_accuracy: 0.0494 - val_loss: 5.5595\n",
      "Epoch 2/25\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 148ms/step - accuracy: 0.0639 - loss: 4.5506 - val_accuracy: 0.0291 - val_loss: 6.1502\n",
      "Epoch 3/25\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 146ms/step - accuracy: 0.0617 - loss: 4.1478 - val_accuracy: 0.0286 - val_loss: 6.0771\n",
      "Epoch 4/25\n",
      "\u001b[1m413/413\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 148ms/step - accuracy: 0.0619 - loss: 3.9984 - val_accuracy: 0.0170 - val_loss: 7.1596\n",
      "Processed cleaned_76. Le PP en Limonese.txt: normalized beginning validation loss = 0.6186026792418141, normalized final validation loss = 0.7966498915034854\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 149ms/step - accuracy: 0.0479 - loss: 7.4752 - val_accuracy: 0.0511 - val_loss: 4.3611\n",
      "Epoch 2/25\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.0742 - loss: 3.9248 - val_accuracy: 0.0367 - val_loss: 5.1071\n",
      "Epoch 3/25\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.0767 - loss: 3.7464 - val_accuracy: 0.0291 - val_loss: 4.8927\n",
      "Epoch 4/25\n",
      "\u001b[1m305/305\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.0791 - loss: 3.6575 - val_accuracy: 0.0164 - val_loss: 5.4093\n",
      "Processed cleaned_31. Le PP en georgien.txt: normalized beginning validation loss = 0.48525626044951103, normalized final validation loss = 0.6018941129700367\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 150ms/step - accuracy: 0.0353 - loss: 6.9979 - val_accuracy: 0.0192 - val_loss: 6.2377\n",
      "Epoch 2/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 147ms/step - accuracy: 0.0541 - loss: 4.3669 - val_accuracy: 0.0063 - val_loss: 7.0749\n",
      "Epoch 3/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 148ms/step - accuracy: 0.0535 - loss: 4.1257 - val_accuracy: 0.0129 - val_loss: 7.3764\n",
      "Epoch 4/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 147ms/step - accuracy: 0.0562 - loss: 4.0114 - val_accuracy: 0.0152 - val_loss: 7.1708\n",
      "Processed cleaned_PP-5534 Oudih.txt: normalized beginning validation loss = 0.6940604671629723, normalized final validation loss = 0.7978853857613156\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 148ms/step - accuracy: 0.0284 - loss: 7.5777 - val_accuracy: 0.0257 - val_loss: 5.8782\n",
      "Epoch 2/25\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 147ms/step - accuracy: 0.0462 - loss: 4.7825 - val_accuracy: 0.0159 - val_loss: 6.8473\n",
      "Epoch 3/25\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 147ms/step - accuracy: 0.0454 - loss: 4.2952 - val_accuracy: 0.0250 - val_loss: 5.8472\n",
      "Epoch 4/25\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 147ms/step - accuracy: 0.0467 - loss: 4.1154 - val_accuracy: 0.0115 - val_loss: 7.4164\n",
      "Epoch 5/25\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 146ms/step - accuracy: 0.0520 - loss: 3.9778 - val_accuracy: 0.0162 - val_loss: 7.3930\n",
      "Epoch 6/25\n",
      "\u001b[1m387/387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 148ms/step - accuracy: 0.0604 - loss: 3.8227 - val_accuracy: 0.0154 - val_loss: 7.5117\n",
      "Processed cleaned_81. Le PP en Esperanto Reformate.txt: normalized beginning validation loss = 0.6540602926823728, normalized final validation loss = 0.8358258725716855\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 150ms/step - accuracy: 0.0241 - loss: 7.3110 - val_accuracy: 0.0144 - val_loss: 6.1225\n",
      "Epoch 2/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0421 - loss: 4.6991 - val_accuracy: 0.0106 - val_loss: 6.9634\n",
      "Epoch 3/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0416 - loss: 4.3041 - val_accuracy: 0.0157 - val_loss: 8.1336\n",
      "Epoch 4/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 148ms/step - accuracy: 0.0432 - loss: 4.1603 - val_accuracy: 0.0051 - val_loss: 9.4832\n",
      "Processed cleaned_16. Le PP en Jerriais.txt: normalized beginning validation loss = 0.6812513003150967, normalized final validation loss = 1.0551925311820725\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 148ms/step - accuracy: 0.0296 - loss: 7.0243 - val_accuracy: 0.0233 - val_loss: 6.4440\n",
      "Epoch 2/25\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 147ms/step - accuracy: 0.0483 - loss: 4.5913 - val_accuracy: 0.0074 - val_loss: 7.7871\n",
      "Epoch 3/25\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 147ms/step - accuracy: 0.0473 - loss: 4.2700 - val_accuracy: 0.0098 - val_loss: 7.3826\n",
      "Epoch 4/25\n",
      "\u001b[1m588/588\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 147ms/step - accuracy: 0.0480 - loss: 4.1531 - val_accuracy: 0.0186 - val_loss: 7.4567\n",
      "Processed cleaned_74. Le PP en Vietnamien.txt: normalized beginning validation loss = 0.7170225359560347, normalized final validation loss = 0.8296992302569826\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 148ms/step - accuracy: 0.0197 - loss: 7.6783 - val_accuracy: 0.0142 - val_loss: 5.8719\n",
      "Epoch 2/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 147ms/step - accuracy: 0.0413 - loss: 4.8596 - val_accuracy: 0.0110 - val_loss: 6.5793\n",
      "Epoch 3/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 148ms/step - accuracy: 0.0430 - loss: 4.3595 - val_accuracy: 0.0157 - val_loss: 6.7135\n",
      "Epoch 4/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 147ms/step - accuracy: 0.0443 - loss: 4.1677 - val_accuracy: 0.0170 - val_loss: 7.3913\n",
      "Processed cleaned_65. Le PP en Appenzellois.txt: normalized beginning validation loss = 0.6533617922140942, normalized final validation loss = 0.8224287768450408\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 146ms/step - accuracy: 0.0241 - loss: 8.0967 - val_accuracy: 0.0328 - val_loss: 5.5027\n",
      "Epoch 2/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 143ms/step - accuracy: 0.0459 - loss: 4.8363 - val_accuracy: 0.0274 - val_loss: 5.2282\n",
      "Epoch 3/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 145ms/step - accuracy: 0.0519 - loss: 4.3819 - val_accuracy: 0.0337 - val_loss: 4.9248\n",
      "Epoch 4/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 142ms/step - accuracy: 0.0522 - loss: 4.1540 - val_accuracy: 0.0139 - val_loss: 6.3081\n",
      "Epoch 5/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 141ms/step - accuracy: 0.0542 - loss: 4.0199 - val_accuracy: 0.0169 - val_loss: 6.8281\n",
      "Epoch 6/25\n",
      "\u001b[1m208/208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 142ms/step - accuracy: 0.0597 - loss: 3.8878 - val_accuracy: 0.0174 - val_loss: 6.5013\n",
      "Processed cleaned_11. Le PP en russe.txt: normalized beginning validation loss = 0.612280202120547, normalized final validation loss = 0.7234012008475947\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 149ms/step - accuracy: 0.0302 - loss: 7.2477 - val_accuracy: 0.0257 - val_loss: 5.8802\n",
      "Epoch 2/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 147ms/step - accuracy: 0.0451 - loss: 4.6250 - val_accuracy: 0.0177 - val_loss: 6.6128\n",
      "Epoch 3/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 148ms/step - accuracy: 0.0441 - loss: 4.2649 - val_accuracy: 0.0111 - val_loss: 8.0335\n",
      "Epoch 4/25\n",
      "\u001b[1m527/527\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 147ms/step - accuracy: 0.0457 - loss: 4.1329 - val_accuracy: 0.0145 - val_loss: 7.8866\n",
      "Processed cleaned_4. Le PP en lithuanien.txt: normalized beginning validation loss = 0.654281541976161, normalized final validation loss = 0.8775327439427612\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 148ms/step - accuracy: 0.0261 - loss: 7.3201 - val_accuracy: 0.0265 - val_loss: 5.8187\n",
      "Epoch 2/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 147ms/step - accuracy: 0.0450 - loss: 4.6252 - val_accuracy: 0.0220 - val_loss: 5.9445\n",
      "Epoch 3/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 147ms/step - accuracy: 0.0441 - loss: 4.2601 - val_accuracy: 0.0199 - val_loss: 6.7077\n",
      "Epoch 4/25\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 147ms/step - accuracy: 0.0462 - loss: 4.1168 - val_accuracy: 0.0177 - val_loss: 7.1168\n",
      "Processed cleaned_26. Le PP en bulgarien.txt: normalized beginning validation loss = 0.6474482814133354, normalized final validation loss = 0.7918797673408887\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 146ms/step - accuracy: 0.0266 - loss: 7.1285 - val_accuracy: 0.0152 - val_loss: 6.8515\n",
      "Epoch 2/25\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 145ms/step - accuracy: 0.0426 - loss: 4.6260 - val_accuracy: 0.0142 - val_loss: 7.5188\n",
      "Epoch 3/25\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 147ms/step - accuracy: 0.0417 - loss: 4.2979 - val_accuracy: 0.0131 - val_loss: 8.1771\n",
      "Epoch 4/25\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 146ms/step - accuracy: 0.0431 - loss: 4.1815 - val_accuracy: 0.0135 - val_loss: 7.9131\n",
      "Processed cleaned_47. Le PP en Mashi.txt: normalized beginning validation loss = 0.7623615567047743, normalized final validation loss = 0.8804881463798332\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 130ms/step - accuracy: 0.0252 - loss: 7.2775 - val_accuracy: 0.0251 - val_loss: 6.0667\n",
      "Epoch 2/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 129ms/step - accuracy: 0.0427 - loss: 4.6563 - val_accuracy: 0.0170 - val_loss: 6.1969\n",
      "Epoch 3/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 128ms/step - accuracy: 0.0420 - loss: 4.3061 - val_accuracy: 0.0101 - val_loss: 7.7516\n",
      "Epoch 4/25\n",
      "\u001b[1m513/513\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 129ms/step - accuracy: 0.0439 - loss: 4.1664 - val_accuracy: 0.0127 - val_loss: 7.5668\n",
      "Processed cleaned_8. Le PP en tourk.txt: normalized beginning validation loss = 0.6750412517918002, normalized final validation loss = 0.8419503925910043\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 134ms/step - accuracy: 0.0337 - loss: 6.9137 - val_accuracy: 0.0215 - val_loss: 5.8576\n",
      "Epoch 2/25\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 133ms/step - accuracy: 0.0535 - loss: 4.4108 - val_accuracy: 0.0112 - val_loss: 7.3991\n",
      "Epoch 3/25\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 134ms/step - accuracy: 0.0528 - loss: 4.1655 - val_accuracy: 0.0220 - val_loss: 6.6547\n",
      "Epoch 4/25\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 132ms/step - accuracy: 0.0532 - loss: 4.0696 - val_accuracy: 0.0215 - val_loss: 6.6342\n",
      "Processed cleaned_PP-2995_dzongka.txt: normalized beginning validation loss = 0.651773731635587, normalized final validation loss = 0.7381875511326448\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 148ms/step - accuracy: 0.0490 - loss: 6.3827 - val_accuracy: 0.0081 - val_loss: 6.8226\n",
      "Epoch 2/25\n",
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 148ms/step - accuracy: 0.0748 - loss: 4.3125 - val_accuracy: 0.0255 - val_loss: 5.3369\n",
      "Epoch 3/25\n",
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 147ms/step - accuracy: 0.0760 - loss: 4.0031 - val_accuracy: 0.0172 - val_loss: 5.9290\n",
      "Epoch 4/25\n",
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 147ms/step - accuracy: 0.0768 - loss: 3.8946 - val_accuracy: 0.0339 - val_loss: 5.6123\n",
      "Epoch 5/25\n",
      "\u001b[1m917/917\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 147ms/step - accuracy: 0.0792 - loss: 3.8206 - val_accuracy: 0.0268 - val_loss: 5.8273\n",
      "Processed cleaned_34. Le PP en japonais.txt: normalized beginning validation loss = 0.7591448997059246, normalized final validation loss = 0.6484018817867779\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 146ms/step - accuracy: 0.0377 - loss: 7.4422 - val_accuracy: 0.0409 - val_loss: 5.2239\n",
      "Epoch 2/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 142ms/step - accuracy: 0.0648 - loss: 4.3866 - val_accuracy: 0.0202 - val_loss: 5.7411\n",
      "Epoch 3/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 142ms/step - accuracy: 0.0652 - loss: 4.0631 - val_accuracy: 0.0233 - val_loss: 5.9348\n",
      "Epoch 4/25\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 141ms/step - accuracy: 0.0662 - loss: 3.9257 - val_accuracy: 0.0170 - val_loss: 6.6394\n",
      "Processed cleaned_13. Le PP en Urdu indien.txt: normalized beginning validation loss = 0.5812585574343649, normalized final validation loss = 0.7387667786003392\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 149ms/step - accuracy: 0.0276 - loss: 7.2518 - val_accuracy: 0.0280 - val_loss: 5.8432\n",
      "Epoch 2/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 147ms/step - accuracy: 0.0453 - loss: 4.5974 - val_accuracy: 0.0125 - val_loss: 6.8760\n",
      "Epoch 3/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 148ms/step - accuracy: 0.0443 - loss: 4.2671 - val_accuracy: 0.0141 - val_loss: 7.4449\n",
      "Epoch 4/25\n",
      "\u001b[1m528/528\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 148ms/step - accuracy: 0.0464 - loss: 4.1392 - val_accuracy: 0.0121 - val_loss: 8.5888\n",
      "Processed cleaned_62. Le PP en Allemand (CSS).txt: normalized beginning validation loss = 0.6501689049235458, normalized final validation loss = 0.9556712031635249\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 149ms/step - accuracy: 0.0333 - loss: 7.0671 - val_accuracy: 0.0097 - val_loss: 6.4309\n",
      "Epoch 2/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 148ms/step - accuracy: 0.0486 - loss: 4.5156 - val_accuracy: 0.0222 - val_loss: 6.5591\n",
      "Epoch 3/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0473 - loss: 4.2242 - val_accuracy: 0.0152 - val_loss: 7.7063\n",
      "Epoch 4/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0488 - loss: 4.1074 - val_accuracy: 0.0190 - val_loss: 6.9353\n",
      "Processed cleaned_1. Le PP en polonais.txt: normalized beginning validation loss = 0.7155655801748779, normalized final validation loss = 0.7716857023024859\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 148ms/step - accuracy: 0.0421 - loss: 7.1683 - val_accuracy: 0.0273 - val_loss: 6.2954\n",
      "Epoch 2/25\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 146ms/step - accuracy: 0.0597 - loss: 4.6823 - val_accuracy: 0.0172 - val_loss: 5.9456\n",
      "Epoch 3/25\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 147ms/step - accuracy: 0.0561 - loss: 4.2625 - val_accuracy: 0.0196 - val_loss: 6.8704\n",
      "Epoch 4/25\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 147ms/step - accuracy: 0.0557 - loss: 4.1199 - val_accuracy: 0.0133 - val_loss: 7.7979\n",
      "Epoch 5/25\n",
      "\u001b[1m570/570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 147ms/step - accuracy: 0.0580 - loss: 4.0278 - val_accuracy: 0.0114 - val_loss: 8.1232\n",
      "Processed cleaned_24. Le PP en Samogitien.txt: normalized beginning validation loss = 0.700485769495597, normalized final validation loss = 0.9038603487558651\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 148ms/step - accuracy: 0.0268 - loss: 7.4999 - val_accuracy: 0.0267 - val_loss: 5.8217\n",
      "Epoch 2/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 148ms/step - accuracy: 0.0452 - loss: 4.7654 - val_accuracy: 0.0182 - val_loss: 6.0493\n",
      "Epoch 3/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 147ms/step - accuracy: 0.0450 - loss: 4.3031 - val_accuracy: 0.0144 - val_loss: 6.7510\n",
      "Epoch 4/25\n",
      "\u001b[1m425/425\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 147ms/step - accuracy: 0.0483 - loss: 4.1187 - val_accuracy: 0.0174 - val_loss: 6.2907\n",
      "Processed cleaned_PP-3974  espagnol.txt: normalized beginning validation loss = 0.647776918853557, normalized final validation loss = 0.699965064323118\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 148ms/step - accuracy: 0.0257 - loss: 7.2618 - val_accuracy: 0.0181 - val_loss: 6.1094\n",
      "Epoch 2/25\n",
      "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 147ms/step - accuracy: 0.0438 - loss: 4.6208 - val_accuracy: 0.0156 - val_loss: 6.9865\n",
      "Epoch 3/25\n",
      "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 146ms/step - accuracy: 0.0433 - loss: 4.2627 - val_accuracy: 0.0068 - val_loss: 8.5582\n",
      "Epoch 4/25\n",
      "\u001b[1m517/517\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 147ms/step - accuracy: 0.0442 - loss: 4.1352 - val_accuracy: 0.0103 - val_loss: 8.5745\n",
      "Processed cleaned_87. Le PP en Javanais.txt: normalized beginning validation loss = 0.6797884021068645, normalized final validation loss = 0.9540785265925574\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 149ms/step - accuracy: 0.0309 - loss: 7.5288 - val_accuracy: 0.0321 - val_loss: 5.6968\n",
      "Epoch 2/25\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 147ms/step - accuracy: 0.0504 - loss: 4.7102 - val_accuracy: 0.0229 - val_loss: 6.0602\n",
      "Epoch 3/25\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 147ms/step - accuracy: 0.0496 - loss: 4.2547 - val_accuracy: 0.0153 - val_loss: 6.6002\n",
      "Epoch 4/25\n",
      "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 147ms/step - accuracy: 0.0503 - loss: 4.0860 - val_accuracy: 0.0179 - val_loss: 6.6738\n",
      "Processed cleaned_2. Le PP en esperanto.txt: normalized beginning validation loss = 0.6338839488104268, normalized final validation loss = 0.7425926404891833\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 148ms/step - accuracy: 0.0267 - loss: 7.2471 - val_accuracy: 0.0178 - val_loss: 6.0610\n",
      "Epoch 2/25\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 147ms/step - accuracy: 0.0433 - loss: 4.6567 - val_accuracy: 0.0145 - val_loss: 7.0580\n",
      "Epoch 3/25\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 146ms/step - accuracy: 0.0422 - loss: 4.2918 - val_accuracy: 0.0141 - val_loss: 7.9302\n",
      "Epoch 4/25\n",
      "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 147ms/step - accuracy: 0.0439 - loss: 4.1590 - val_accuracy: 0.0041 - val_loss: 9.7735\n",
      "Processed cleaned_33. Le PP en croatian.txt: normalized beginning validation loss = 0.6744021755942753, normalized final validation loss = 1.0874873939265364\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 148ms/step - accuracy: 0.0417 - loss: 7.0458 - val_accuracy: 0.0473 - val_loss: 4.6763\n",
      "Epoch 2/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 146ms/step - accuracy: 0.0639 - loss: 4.3187 - val_accuracy: 0.0429 - val_loss: 4.7942\n",
      "Epoch 3/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 147ms/step - accuracy: 0.0692 - loss: 4.0317 - val_accuracy: 0.0337 - val_loss: 4.6818\n",
      "Epoch 4/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 147ms/step - accuracy: 0.0708 - loss: 3.8628 - val_accuracy: 0.0455 - val_loss: 4.5361\n",
      "Epoch 5/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 146ms/step - accuracy: 0.0707 - loss: 3.7746 - val_accuracy: 0.0373 - val_loss: 4.7616\n",
      "Epoch 6/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 146ms/step - accuracy: 0.0721 - loss: 3.7193 - val_accuracy: 0.0358 - val_loss: 4.9071\n",
      "Epoch 7/25\n",
      "\u001b[1m418/418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 147ms/step - accuracy: 0.0741 - loss: 3.6738 - val_accuracy: 0.0339 - val_loss: 4.9364\n",
      "Processed cleaned_PP-0180_berbere-amazighe.txt: normalized beginning validation loss = 0.5203322851800158, normalized final validation loss = 0.5492697827416669\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 148ms/step - accuracy: 0.0209 - loss: 7.4079 - val_accuracy: 0.0088 - val_loss: 6.0753\n",
      "Epoch 2/25\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 147ms/step - accuracy: 0.0410 - loss: 4.7782 - val_accuracy: 0.0170 - val_loss: 6.8163\n",
      "Epoch 3/25\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 146ms/step - accuracy: 0.0410 - loss: 4.3614 - val_accuracy: 0.0147 - val_loss: 7.4142\n",
      "Epoch 4/25\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 146ms/step - accuracy: 0.0415 - loss: 4.2182 - val_accuracy: 0.0098 - val_loss: 8.5622\n",
      "Processed cleaned_71. Le PP en Kinyarwanda  .txt: normalized beginning validation loss = 0.6759945338209351, normalized final validation loss = 0.9527134662015304\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 149ms/step - accuracy: 0.0381 - loss: 7.4292 - val_accuracy: 0.0440 - val_loss: 5.7175\n",
      "Epoch 2/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 142ms/step - accuracy: 0.0574 - loss: 4.6414 - val_accuracy: 0.0159 - val_loss: 6.7661\n",
      "Epoch 3/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 140ms/step - accuracy: 0.0561 - loss: 4.2194 - val_accuracy: 0.0204 - val_loss: 6.4574\n",
      "Epoch 4/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 142ms/step - accuracy: 0.0570 - loss: 4.0482 - val_accuracy: 0.0183 - val_loss: 7.1009\n",
      "Processed cleaned_21 B Le PP en Berbere amazighe.txt: normalized beginning validation loss = 0.6361813335636712, normalized final validation loss = 0.7901126380893516\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 148ms/step - accuracy: 0.0223 - loss: 7.2323 - val_accuracy: 0.0091 - val_loss: 6.7426\n",
      "Epoch 2/25\n",
      "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 146ms/step - accuracy: 0.0407 - loss: 4.6187 - val_accuracy: 0.0169 - val_loss: 7.2226\n",
      "Epoch 3/25\n",
      "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 146ms/step - accuracy: 0.0405 - loss: 4.2974 - val_accuracy: 0.0076 - val_loss: 9.5392\n",
      "Epoch 4/25\n",
      "\u001b[1m538/538\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 146ms/step - accuracy: 0.0421 - loss: 4.1761 - val_accuracy: 0.0145 - val_loss: 8.0782\n",
      "Processed cleaned_6. Le PP en estonien.txt: normalized beginning validation loss = 0.7502495108331777, normalized final validation loss = 0.8988552334368684\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 147ms/step - accuracy: 0.0347 - loss: 7.4221 - val_accuracy: 0.0299 - val_loss: 5.7948\n",
      "Epoch 2/25\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 147ms/step - accuracy: 0.0505 - loss: 4.6777 - val_accuracy: 0.0128 - val_loss: 6.5883\n",
      "Epoch 3/25\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 147ms/step - accuracy: 0.0494 - loss: 4.2295 - val_accuracy: 0.0258 - val_loss: 6.0312\n",
      "Epoch 4/25\n",
      "\u001b[1m451/451\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 147ms/step - accuracy: 0.0497 - loss: 4.0767 - val_accuracy: 0.0228 - val_loss: 7.1745\n",
      "Processed cleaned_PP-0803_papiamento.txt: normalized beginning validation loss = 0.6447815642058801, normalized final validation loss = 0.7983018862304373\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 143ms/step - accuracy: 0.0248 - loss: 7.6926 - val_accuracy: 0.0234 - val_loss: 5.8867\n",
      "Epoch 2/25\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 143ms/step - accuracy: 0.0442 - loss: 4.8145 - val_accuracy: 0.0224 - val_loss: 6.1305\n",
      "Epoch 3/25\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 141ms/step - accuracy: 0.0444 - loss: 4.3210 - val_accuracy: 0.0241 - val_loss: 6.1621\n",
      "Epoch 4/25\n",
      "\u001b[1m346/346\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 143ms/step - accuracy: 0.0458 - loss: 4.1363 - val_accuracy: 0.0117 - val_loss: 8.0569\n",
      "Processed cleaned_25. Le PP en catalan.txt: normalized beginning validation loss = 0.6550093301207396, normalized final validation loss = 0.8964879190507192\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 149ms/step - accuracy: 0.0415 - loss: 7.4698 - val_accuracy: 0.0426 - val_loss: 5.5853\n",
      "Epoch 2/25\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 147ms/step - accuracy: 0.0615 - loss: 4.5890 - val_accuracy: 0.0125 - val_loss: 6.1802\n",
      "Epoch 3/25\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 147ms/step - accuracy: 0.0600 - loss: 4.1710 - val_accuracy: 0.0119 - val_loss: 7.1245\n",
      "Epoch 4/25\n",
      "\u001b[1m406/406\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 147ms/step - accuracy: 0.0611 - loss: 4.0101 - val_accuracy: 0.0167 - val_loss: 6.9332\n",
      "Processed cleaned_84. Le PP en Crokle vincentien.txt: normalized beginning validation loss = 0.6214702186499861, normalized final validation loss = 0.7714546373925464\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 148ms/step - accuracy: 0.0237 - loss: 8.5416 - val_accuracy: 0.0143 - val_loss: 6.7495\n",
      "Epoch 2/25\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 141ms/step - accuracy: 0.0479 - loss: 5.2607 - val_accuracy: 0.0309 - val_loss: 4.9250\n",
      "Epoch 3/25\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 140ms/step - accuracy: 0.0559 - loss: 4.2774 - val_accuracy: 0.0306 - val_loss: 4.8999\n",
      "Epoch 4/25\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 147ms/step - accuracy: 0.0575 - loss: 4.1036 - val_accuracy: 0.0269 - val_loss: 4.9877\n",
      "Epoch 5/25\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 142ms/step - accuracy: 0.0591 - loss: 3.9898 - val_accuracy: 0.0178 - val_loss: 5.6261\n",
      "Epoch 6/25\n",
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 140ms/step - accuracy: 0.0616 - loss: 3.8977 - val_accuracy: 0.0099 - val_loss: 6.5663\n",
      "Processed cleaned_27. Le PP en armenien.txt: normalized beginning validation loss = 0.7510162961554383, normalized final validation loss = 0.7306268207695482\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 152ms/step - accuracy: 0.0590 - loss: 7.9158 - val_accuracy: 0.0607 - val_loss: 3.9825\n",
      "Epoch 2/25\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 146ms/step - accuracy: 0.0891 - loss: 3.6350 - val_accuracy: 0.0608 - val_loss: 4.2827\n",
      "Epoch 3/25\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 147ms/step - accuracy: 0.0922 - loss: 3.4866 - val_accuracy: 0.0142 - val_loss: 5.1451\n",
      "Epoch 4/25\n",
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 145ms/step - accuracy: 0.0945 - loss: 3.4139 - val_accuracy: 0.0165 - val_loss: 5.3364\n",
      "Processed cleaned_32. Le PP en hebreu.txt: normalized beginning validation loss = 0.44312673395269997, normalized final validation loss = 0.593779145167393\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 148ms/step - accuracy: 0.0459 - loss: 7.2500 - val_accuracy: 0.0445 - val_loss: 5.4467\n",
      "Epoch 2/25\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 147ms/step - accuracy: 0.0623 - loss: 4.4727 - val_accuracy: 0.0285 - val_loss: 5.6982\n",
      "Epoch 3/25\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 146ms/step - accuracy: 0.0606 - loss: 4.1152 - val_accuracy: 0.0208 - val_loss: 6.2200\n",
      "Epoch 4/25\n",
      "\u001b[1m467/467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 146ms/step - accuracy: 0.0616 - loss: 3.9774 - val_accuracy: 0.0263 - val_loss: 6.9032\n",
      "Processed cleaned_43. Le PP en Sranan.txt: normalized beginning validation loss = 0.6060478164383334, normalized final validation loss = 0.7681149933761904\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 148ms/step - accuracy: 0.0264 - loss: 7.2929 - val_accuracy: 0.0184 - val_loss: 5.8505\n",
      "Epoch 2/25\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 147ms/step - accuracy: 0.0474 - loss: 4.5961 - val_accuracy: 0.0173 - val_loss: 6.6707\n",
      "Epoch 3/25\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 147ms/step - accuracy: 0.0475 - loss: 4.2520 - val_accuracy: 0.0143 - val_loss: 7.8990\n",
      "Epoch 4/25\n",
      "\u001b[1m445/445\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 146ms/step - accuracy: 0.0495 - loss: 4.1145 - val_accuracy: 0.0173 - val_loss: 7.3096\n",
      "Processed cleaned_3. Le PP en viet.txt: normalized beginning validation loss = 0.6509799401045642, normalized final validation loss = 0.8133307087631162\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 147ms/step - accuracy: 0.0414 - loss: 6.6130 - val_accuracy: 0.0033 - val_loss: 6.1181\n",
      "Epoch 2/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 146ms/step - accuracy: 0.0616 - loss: 4.0471 - val_accuracy: 0.0198 - val_loss: 6.0383\n",
      "Epoch 3/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 146ms/step - accuracy: 0.0630 - loss: 3.9058 - val_accuracy: 0.0197 - val_loss: 6.3686\n",
      "Epoch 4/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0677 - loss: 3.8176 - val_accuracy: 0.0238 - val_loss: 6.4471\n",
      "Epoch 5/25\n",
      "\u001b[1m597/597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 146ms/step - accuracy: 0.0754 - loss: 3.7136 - val_accuracy: 0.0277 - val_loss: 6.5838\n",
      "Processed cleaned_67. Le PP en Jawi.txt: normalized beginning validation loss = 0.6807542587361499, normalized final validation loss = 0.732579863096729\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 149ms/step - accuracy: 0.0426 - loss: 7.6265 - val_accuracy: 0.0421 - val_loss: 4.7984\n",
      "Epoch 2/25\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 145ms/step - accuracy: 0.0656 - loss: 4.2942 - val_accuracy: 0.0377 - val_loss: 5.1381\n",
      "Epoch 3/25\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 147ms/step - accuracy: 0.0687 - loss: 3.9827 - val_accuracy: 0.0290 - val_loss: 5.2515\n",
      "Epoch 4/25\n",
      "\u001b[1m304/304\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 144ms/step - accuracy: 0.0687 - loss: 3.8325 - val_accuracy: 0.0266 - val_loss: 5.5910\n",
      "Processed cleaned_57. Le PP en Karne.txt: normalized beginning validation loss = 0.5339159306709194, normalized final validation loss = 0.6221026096170512\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 148ms/step - accuracy: 0.0384 - loss: 7.4087 - val_accuracy: 0.0638 - val_loss: 5.5742\n",
      "Epoch 2/25\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 147ms/step - accuracy: 0.0650 - loss: 4.5136 - val_accuracy: 0.0233 - val_loss: 5.8379\n",
      "Epoch 3/25\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 146ms/step - accuracy: 0.0619 - loss: 4.1313 - val_accuracy: 0.0161 - val_loss: 6.3014\n",
      "Epoch 4/25\n",
      "\u001b[1m401/401\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 146ms/step - accuracy: 0.0628 - loss: 3.9746 - val_accuracy: 0.0175 - val_loss: 6.7504\n",
      "Processed cleaned_63. Le PP en Maya Tojobal.txt: normalized beginning validation loss = 0.6202346182773866, normalized final validation loss = 0.7511139217431051\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 152ms/step - accuracy: 0.1907 - loss: 6.9361 - val_accuracy: 0.2276 - val_loss: 4.6693\n",
      "Epoch 2/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 147ms/step - accuracy: 0.2424 - loss: 3.2708 - val_accuracy: 0.2335 - val_loss: 3.5300\n",
      "Epoch 3/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.2514 - loss: 3.1428 - val_accuracy: 0.2548 - val_loss: 3.1315\n",
      "Epoch 4/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 145ms/step - accuracy: 0.2586 - loss: 3.0253 - val_accuracy: 0.2518 - val_loss: 2.9679\n",
      "Epoch 5/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 147ms/step - accuracy: 0.2610 - loss: 2.9478 - val_accuracy: 0.2614 - val_loss: 2.9022\n",
      "Epoch 6/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 148ms/step - accuracy: 0.2636 - loss: 2.8664 - val_accuracy: 0.2580 - val_loss: 2.8441\n",
      "Epoch 7/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 149ms/step - accuracy: 0.2632 - loss: 2.8119 - val_accuracy: 0.2576 - val_loss: 2.8490\n",
      "Epoch 8/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2649 - loss: 2.7641 - val_accuracy: 0.2602 - val_loss: 2.7885\n",
      "Epoch 9/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 145ms/step - accuracy: 0.2648 - loss: 2.7191 - val_accuracy: 0.2526 - val_loss: 2.7438\n",
      "Epoch 10/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.2653 - loss: 2.6755 - val_accuracy: 0.2536 - val_loss: 2.7106\n",
      "Epoch 11/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 147ms/step - accuracy: 0.2664 - loss: 2.6326 - val_accuracy: 0.2551 - val_loss: 2.7533\n",
      "Epoch 12/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2669 - loss: 2.6038 - val_accuracy: 0.2657 - val_loss: 2.6161\n",
      "Epoch 13/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2677 - loss: 2.5649 - val_accuracy: 0.2671 - val_loss: 2.5633\n",
      "Epoch 14/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.2677 - loss: 2.5292 - val_accuracy: 0.2682 - val_loss: 2.5198\n",
      "Epoch 15/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2690 - loss: 2.4975 - val_accuracy: 0.2676 - val_loss: 2.5084\n",
      "Epoch 16/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2695 - loss: 2.4770 - val_accuracy: 0.2665 - val_loss: 2.5059\n",
      "Epoch 17/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2698 - loss: 2.4585 - val_accuracy: 0.2701 - val_loss: 2.4644\n",
      "Epoch 18/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 149ms/step - accuracy: 0.2696 - loss: 2.4417 - val_accuracy: 0.2535 - val_loss: 2.4847\n",
      "Epoch 19/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2709 - loss: 2.4293 - val_accuracy: 0.2529 - val_loss: 2.4876\n",
      "Epoch 20/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2714 - loss: 2.4094 - val_accuracy: 0.2672 - val_loss: 2.4466\n",
      "Epoch 21/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 150ms/step - accuracy: 0.2714 - loss: 2.3984 - val_accuracy: 0.2679 - val_loss: 2.4145\n",
      "Epoch 22/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 147ms/step - accuracy: 0.2726 - loss: 2.3846 - val_accuracy: 0.2681 - val_loss: 2.4197\n",
      "Epoch 23/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 146ms/step - accuracy: 0.2729 - loss: 2.3702 - val_accuracy: 0.2685 - val_loss: 2.3978\n",
      "Epoch 24/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 144ms/step - accuracy: 0.2740 - loss: 2.3617 - val_accuracy: 0.2679 - val_loss: 2.4637\n",
      "Epoch 25/25\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 151ms/step - accuracy: 0.2723 - loss: 2.3516 - val_accuracy: 0.2707 - val_loss: 2.3717\n",
      "Processed cleaned_PP-5533 Oulta.txt: normalized beginning validation loss = 0.5195453911089911, normalized final validation loss = 0.26389994991656834\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 149ms/step - accuracy: 0.0298 - loss: 7.3559 - val_accuracy: 0.0256 - val_loss: 5.5690\n",
      "Epoch 2/25\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 146ms/step - accuracy: 0.0481 - loss: 4.5728 - val_accuracy: 0.0186 - val_loss: 6.2628\n",
      "Epoch 3/25\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 145ms/step - accuracy: 0.0469 - loss: 4.2240 - val_accuracy: 0.0067 - val_loss: 7.5218\n",
      "Epoch 4/25\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 147ms/step - accuracy: 0.0480 - loss: 4.0912 - val_accuracy: 0.0077 - val_loss: 8.3090\n",
      "Processed cleaned_PP-2980 yiddish de Varsovie.txt: normalized beginning validation loss = 0.6196594762283065, normalized final validation loss = 0.9245376604532183\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 149ms/step - accuracy: 0.0287 - loss: 7.0175 - val_accuracy: 0.0272 - val_loss: 6.4263\n",
      "Epoch 2/25\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 147ms/step - accuracy: 0.0463 - loss: 4.6429 - val_accuracy: 0.0165 - val_loss: 6.5958\n",
      "Epoch 3/25\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 148ms/step - accuracy: 0.0455 - loss: 4.2640 - val_accuracy: 0.0158 - val_loss: 7.6956\n",
      "Epoch 4/25\n",
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 147ms/step - accuracy: 0.0459 - loss: 4.1484 - val_accuracy: 0.0194 - val_loss: 7.3467\n",
      "Processed cleaned_64. Le PP en Balinais.txt: normalized beginning validation loss = 0.7150530458396275, normalized final validation loss = 0.8174637198514182\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 149ms/step - accuracy: 0.0335 - loss: 6.9866 - val_accuracy: 0.0183 - val_loss: 6.0629\n",
      "Epoch 2/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0524 - loss: 4.4440 - val_accuracy: 0.0194 - val_loss: 6.3970\n",
      "Epoch 3/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0510 - loss: 4.1658 - val_accuracy: 0.0166 - val_loss: 7.0429\n",
      "Epoch 4/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0522 - loss: 4.0575 - val_accuracy: 0.0172 - val_loss: 6.7554\n",
      "Processed cleaned_PP-1646 quechua_cuzquenien.txt: normalized beginning validation loss = 0.6746138745588353, normalized final validation loss = 0.7516684775269599\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 149ms/step - accuracy: 0.0374 - loss: 7.2293 - val_accuracy: 0.0349 - val_loss: 5.1850\n",
      "Epoch 2/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 147ms/step - accuracy: 0.0591 - loss: 4.2593 - val_accuracy: 0.0123 - val_loss: 6.3210\n",
      "Epoch 3/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 147ms/step - accuracy: 0.0600 - loss: 4.0336 - val_accuracy: 0.0125 - val_loss: 7.4887\n",
      "Epoch 4/25\n",
      "\u001b[1m397/397\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 145ms/step - accuracy: 0.0626 - loss: 3.9218 - val_accuracy: 0.0188 - val_loss: 6.3753\n",
      "Processed cleaned_42. Le PP en Armnien.txt: normalized beginning validation loss = 0.5769367681716508, normalized final validation loss = 0.7093794605320367\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 149ms/step - accuracy: 0.0340 - loss: 6.6009 - val_accuracy: 0.0303 - val_loss: 5.3006\n",
      "Epoch 2/25\n",
      "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 147ms/step - accuracy: 0.0539 - loss: 4.2289 - val_accuracy: 0.0272 - val_loss: 5.8115\n",
      "Epoch 3/25\n",
      "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 147ms/step - accuracy: 0.0573 - loss: 4.0361 - val_accuracy: 0.0195 - val_loss: 6.0690\n",
      "Epoch 4/25\n",
      "\u001b[1m652/652\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 148ms/step - accuracy: 0.0633 - loss: 3.9105 - val_accuracy: 0.0173 - val_loss: 6.7842\n",
      "Processed cleaned_83. Le PP en Khmer-Surin.txt: normalized beginning validation loss = 0.5897958089610519, normalized final validation loss = 0.7548717110075054\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m596/596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 149ms/step - accuracy: 0.0331 - loss: 6.9682 - val_accuracy: 0.0139 - val_loss: 6.3806\n",
      "Epoch 2/25\n",
      "\u001b[1m596/596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 148ms/step - accuracy: 0.0506 - loss: 4.4649 - val_accuracy: 0.0104 - val_loss: 7.8401\n",
      "Epoch 3/25\n",
      "\u001b[1m596/596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0499 - loss: 4.2022 - val_accuracy: 0.0118 - val_loss: 7.3034\n",
      "Epoch 4/25\n",
      "\u001b[1m596/596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0514 - loss: 4.0990 - val_accuracy: 0.0144 - val_loss: 7.5613\n",
      "Processed cleaned_72. Le PP en Ojibwe.txt: normalized beginning validation loss = 0.7099649487711142, normalized final validation loss = 0.8413419835617791\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 149ms/step - accuracy: 0.0283 - loss: 6.9958 - val_accuracy: 0.0276 - val_loss: 5.5312\n",
      "Epoch 2/25\n",
      "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 148ms/step - accuracy: 0.0506 - loss: 4.4775 - val_accuracy: 0.0223 - val_loss: 6.0980\n",
      "Epoch 3/25\n",
      "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - accuracy: 0.0521 - loss: 4.1840 - val_accuracy: 0.0107 - val_loss: 6.5907\n",
      "Epoch 4/25\n",
      "\u001b[1m559/559\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 147ms/step - accuracy: 0.0577 - loss: 4.0334 - val_accuracy: 0.0115 - val_loss: 7.3776\n",
      "Processed cleaned_33. Le PP en kazach.txt: normalized beginning validation loss = 0.6154573844252533, normalized final validation loss = 0.8208998752503643\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m511/511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 149ms/step - accuracy: 0.0220 - loss: 7.3233 - val_accuracy: 0.0116 - val_loss: 6.3456\n",
      "Epoch 2/25\n",
      "\u001b[1m511/511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0404 - loss: 4.7303 - val_accuracy: 0.0137 - val_loss: 7.2245\n",
      "Epoch 3/25\n",
      "\u001b[1m511/511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0401 - loss: 4.3365 - val_accuracy: 0.0141 - val_loss: 7.8202\n",
      "Epoch 4/25\n",
      "\u001b[1m511/511\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0426 - loss: 4.1799 - val_accuracy: 0.0157 - val_loss: 8.1393\n",
      "Processed cleaned_PP-3434_kirundi.txt: normalized beginning validation loss = 0.7060712264873648, normalized final validation loss = 0.9056508232566268\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 144ms/step - accuracy: 0.0404 - loss: 6.5572 - val_accuracy: 0.0194 - val_loss: 6.1120\n",
      "Epoch 2/25\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 142ms/step - accuracy: 0.0575 - loss: 4.2466 - val_accuracy: 0.0119 - val_loss: 7.2301\n",
      "Epoch 3/25\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 144ms/step - accuracy: 0.0569 - loss: 4.0728 - val_accuracy: 0.0205 - val_loss: 6.8978\n",
      "Epoch 4/25\n",
      "\u001b[1m737/737\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 141ms/step - accuracy: 0.0573 - loss: 3.9989 - val_accuracy: 0.0164 - val_loss: 6.9971\n",
      "Processed cleaned_18. Le PP en Tibtain.txt: normalized beginning validation loss = 0.6800748058689433, normalized final validation loss = 0.7785656533637607\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 148ms/step - accuracy: 0.0565 - loss: 8.4956 - val_accuracy: 0.0499 - val_loss: 5.7127\n",
      "Epoch 2/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 143ms/step - accuracy: 0.0794 - loss: 4.8555 - val_accuracy: 0.0654 - val_loss: 3.9554\n",
      "Epoch 3/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.0967 - loss: 3.6125 - val_accuracy: 0.0870 - val_loss: 3.9922\n",
      "Epoch 4/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 136ms/step - accuracy: 0.0994 - loss: 3.5153 - val_accuracy: 0.0480 - val_loss: 4.0167\n",
      "Epoch 5/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 142ms/step - accuracy: 0.1006 - loss: 3.4590 - val_accuracy: 0.0535 - val_loss: 3.9313\n",
      "Epoch 6/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 141ms/step - accuracy: 0.1017 - loss: 3.4142 - val_accuracy: 0.0416 - val_loss: 4.0366\n",
      "Epoch 7/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 138ms/step - accuracy: 0.1026 - loss: 3.3766 - val_accuracy: 0.0406 - val_loss: 4.1812\n",
      "Epoch 8/25\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 137ms/step - accuracy: 0.1050 - loss: 3.3424 - val_accuracy: 0.0327 - val_loss: 4.8515\n",
      "Processed cleaned_36. Le PP en bengali.txt: normalized beginning validation loss = 0.6356466212416574, normalized final validation loss = 0.5398209522901418\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 144ms/step - accuracy: 0.0377 - loss: 7.2665 - val_accuracy: 0.0224 - val_loss: 5.7910\n",
      "Epoch 2/25\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 143ms/step - accuracy: 0.0554 - loss: 4.5415 - val_accuracy: 0.0235 - val_loss: 6.4560\n",
      "Epoch 3/25\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 143ms/step - accuracy: 0.0535 - loss: 4.1803 - val_accuracy: 0.0180 - val_loss: 7.0174\n",
      "Epoch 4/25\n",
      "\u001b[1m494/494\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 142ms/step - accuracy: 0.0561 - loss: 4.0284 - val_accuracy: 0.0159 - val_loss: 7.4516\n",
      "Processed cleaned_54. Le PP en royasque tendasque.txt: normalized beginning validation loss = 0.6443570520716836, normalized final validation loss = 0.8291343813405152\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 148ms/step - accuracy: 0.0232 - loss: 7.5650 - val_accuracy: 0.0178 - val_loss: 5.8788\n",
      "Epoch 2/25\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 146ms/step - accuracy: 0.0433 - loss: 4.7777 - val_accuracy: 0.0184 - val_loss: 6.0602\n",
      "Epoch 3/25\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 144ms/step - accuracy: 0.0440 - loss: 4.3272 - val_accuracy: 0.0101 - val_loss: 7.3383\n",
      "Epoch 4/25\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - accuracy: 0.0469 - loss: 4.1481 - val_accuracy: 0.0115 - val_loss: 7.6503\n",
      "Processed cleaned_22. Le PP en Comorien.txt: normalized beginning validation loss = 0.654128153077278, normalized final validation loss = 0.8512404222904172\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 149ms/step - accuracy: 0.0342 - loss: 6.9208 - val_accuracy: 0.0291 - val_loss: 4.8939\n",
      "Epoch 2/25\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0578 - loss: 4.2627 - val_accuracy: 0.0252 - val_loss: 5.1933\n",
      "Epoch 3/25\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 147ms/step - accuracy: 0.0622 - loss: 4.0360 - val_accuracy: 0.0264 - val_loss: 5.3660\n",
      "Epoch 4/25\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 146ms/step - accuracy: 0.0645 - loss: 3.9204 - val_accuracy: 0.0170 - val_loss: 6.3386\n",
      "Processed cleaned_9. Le PP en grecque.txt: normalized beginning validation loss = 0.5445366395761374, normalized final validation loss = 0.7052974906477213\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 150ms/step - accuracy: 0.0419 - loss: 7.3871 - val_accuracy: 0.0396 - val_loss: 5.5582\n",
      "Epoch 2/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 148ms/step - accuracy: 0.0602 - loss: 4.5366 - val_accuracy: 0.0094 - val_loss: 6.3930\n",
      "Epoch 3/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 147ms/step - accuracy: 0.0578 - loss: 4.1481 - val_accuracy: 0.0148 - val_loss: 7.3462\n",
      "Epoch 4/25\n",
      "\u001b[1m427/427\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 147ms/step - accuracy: 0.0585 - loss: 4.0098 - val_accuracy: 0.0131 - val_loss: 7.3761\n",
      "Processed cleaned_44. Le PP en creole jamacain.txt: normalized beginning validation loss = 0.6184588937295441, normalized final validation loss = 0.8207357157024073\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 149ms/step - accuracy: 0.0403 - loss: 7.0859 - val_accuracy: 0.0329 - val_loss: 6.8912\n",
      "Epoch 2/25\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 146ms/step - accuracy: 0.0546 - loss: 4.5014 - val_accuracy: 0.0289 - val_loss: 5.7119\n",
      "Epoch 3/25\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 147ms/step - accuracy: 0.0527 - loss: 4.1587 - val_accuracy: 0.0143 - val_loss: 7.1776\n",
      "Epoch 4/25\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 146ms/step - accuracy: 0.0563 - loss: 4.0072 - val_accuracy: 0.0124 - val_loss: 8.0885\n",
      "Epoch 5/25\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 147ms/step - accuracy: 0.0636 - loss: 3.8598 - val_accuracy: 0.0066 - val_loss: 8.2937\n",
      "Processed cleaned_15. Le PP en franca nova.txt: normalized beginning validation loss = 0.7667757719314643, normalized final validation loss = 0.9228378079653559\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 150ms/step - accuracy: 0.0289 - loss: 7.4692 - val_accuracy: 0.0389 - val_loss: 5.5929\n",
      "Epoch 2/25\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 148ms/step - accuracy: 0.0513 - loss: 4.5991 - val_accuracy: 0.0208 - val_loss: 5.9522\n",
      "Epoch 3/25\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 146ms/step - accuracy: 0.0519 - loss: 4.2032 - val_accuracy: 0.0213 - val_loss: 6.3709\n",
      "Epoch 4/25\n",
      "\u001b[1m386/386\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 145ms/step - accuracy: 0.0527 - loss: 4.0507 - val_accuracy: 0.0115 - val_loss: 7.5527\n",
      "Processed cleaned_85. Le PP en Sarnami.txt: normalized beginning validation loss = 0.6223166961639182, normalized final validation loss = 0.840382599933415\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 149ms/step - accuracy: 0.0270 - loss: 7.2348 - val_accuracy: 0.0101 - val_loss: 6.1393\n",
      "Epoch 2/25\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 146ms/step - accuracy: 0.0455 - loss: 4.6336 - val_accuracy: 0.0123 - val_loss: 7.2596\n",
      "Epoch 3/25\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 147ms/step - accuracy: 0.0441 - loss: 4.2840 - val_accuracy: 0.0097 - val_loss: 8.4869\n",
      "Epoch 4/25\n",
      "\u001b[1m542/542\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 147ms/step - accuracy: 0.0463 - loss: 4.1444 - val_accuracy: 0.0103 - val_loss: 8.2827\n",
      "Processed cleaned_8. Le PP en latvian.txt: normalized beginning validation loss = 0.6831128186538399, normalized final validation loss = 0.921607725560755\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 149ms/step - accuracy: 0.0532 - loss: 7.1784 - val_accuracy: 0.0517 - val_loss: 5.2193\n",
      "Epoch 2/25\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 148ms/step - accuracy: 0.0751 - loss: 4.2706 - val_accuracy: 0.0421 - val_loss: 5.5842\n",
      "Epoch 3/25\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 137ms/step - accuracy: 0.0727 - loss: 3.9733 - val_accuracy: 0.0138 - val_loss: 6.9164\n",
      "Epoch 4/25\n",
      "\u001b[1m437/437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 138ms/step - accuracy: 0.0735 - loss: 3.8545 - val_accuracy: 0.0256 - val_loss: 6.1583\n",
      "Processed cleaned_70. Le PP en Rapa Nui.txt: normalized beginning validation loss = 0.5807513818949593, normalized final validation loss = 0.6852250331348251\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step - accuracy: 0.0170 - loss: 7.7096 - val_accuracy: 0.0086 - val_loss: 5.9868\n",
      "Epoch 2/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 146ms/step - accuracy: 0.0392 - loss: 4.9081 - val_accuracy: 0.0115 - val_loss: 6.5797\n",
      "Epoch 3/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 148ms/step - accuracy: 0.0409 - loss: 4.3943 - val_accuracy: 0.0194 - val_loss: 6.6998\n",
      "Epoch 4/25\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 148ms/step - accuracy: 0.0434 - loss: 4.1939 - val_accuracy: 0.0161 - val_loss: 6.8169\n",
      "Processed cleaned_40. Le PP en Kirundi.txt: normalized beginning validation loss = 0.6661435283941308, normalized final validation loss = 0.7585126148536286\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 139ms/step - accuracy: 0.0247 - loss: 7.5393 - val_accuracy: 0.0227 - val_loss: 5.6096\n",
      "Epoch 2/25\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 139ms/step - accuracy: 0.0470 - loss: 4.6142 - val_accuracy: 0.0148 - val_loss: 6.5392\n",
      "Epoch 3/25\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 140ms/step - accuracy: 0.0486 - loss: 4.2301 - val_accuracy: 0.0132 - val_loss: 7.4973\n",
      "Epoch 4/25\n",
      "\u001b[1m353/353\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 137ms/step - accuracy: 0.0516 - loss: 4.0608 - val_accuracy: 0.0159 - val_loss: 7.0786\n",
      "Processed cleaned_56.  Le PP en Mapuche.txt: normalized beginning validation loss = 0.6241780022731229, normalized final validation loss = 0.7876281199406178\n",
      "Dataset Created\n",
      "Autoencoder Created\n",
      "Epoch 1/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 149ms/step - accuracy: 0.0408 - loss: 7.0601 - val_accuracy: 0.0383 - val_loss: 6.0815\n",
      "Epoch 2/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 147ms/step - accuracy: 0.0560 - loss: 4.4637 - val_accuracy: 0.0193 - val_loss: 6.6390\n",
      "Epoch 3/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 147ms/step - accuracy: 0.0537 - loss: 4.1536 - val_accuracy: 0.0194 - val_loss: 7.1820\n",
      "Epoch 4/25\n",
      "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 145ms/step - accuracy: 0.0547 - loss: 4.0382 - val_accuracy: 0.0139 - val_loss: 8.1306\n",
      "Processed cleaned_82. Le PP en Cebuano.txt: normalized beginning validation loss = 0.6766865082309077, normalized final validation loss = 0.9046849666273414\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename in processed_files:\n",
    "        print(f\"Skipping {filename}: already trained.\")\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    text = load_text(file_path)\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"spm_tokenizer.json\")\n",
    "    input_sequences, total_words = create_sequences(text, sequence_length, tokenizer)\n",
    "    \n",
    "    X_train, X_test = train_test_split(input_sequences, test_size=0.2, random_state=42)\n",
    "    print(\"Dataset Created\")\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model = create_autoencoder(sequence_length, total_words)\n",
    "    print(\"Autoencoder Created\")\n",
    "\n",
    "    batch_size = 32\n",
    "    train_generator = data_generator(X_train, total_words, batch_size)\n",
    "    test_generator = data_generator(X_test, total_words, batch_size)\n",
    "\n",
    "    train_steps = len(X_train) // batch_size\n",
    "    test_steps = len(X_test) // batch_size\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=test_steps,\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    beginning_val_loss = history.history['val_loss'][0]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    normalized_beginning_val_loss = beginning_val_loss / np.log(total_words)\n",
    "    normalized_final_val_loss = final_val_loss / np.log(total_words)\n",
    "    processed_files[filename] = (normalized_beginning_val_loss, normalized_final_val_loss)\n",
    "\n",
    "    with open(trained_files_log, 'a') as f:\n",
    "        f.write(f\"{filename}: {normalized_beginning_val_loss}: {normalized_final_val_loss}\\n\")\n",
    "    \n",
    "    print(f\"Processed {filename}: normalized beginning validation loss = {normalized_beginning_val_loss}, normalized final validation loss = {normalized_final_val_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6404762,
     "sourceId": 10342852,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29615.555465,
   "end_time": "2025-01-02T00:53:18.369149",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-01T16:39:42.813684",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
